---
title: "Why not just using a single indicator?"
author: "Falco J. Bargagli Stoffi"
date: "29/02/2020"
output:
  pdf_document:
    keep_tex: true
---

# Introduction 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'G:\\Il mio Drive\\Research\\Italian Firms\\Zombie Hunting New Data')
```

In this section of the Appendix we check what is the comparative advantage of using our Machine-Learning-based definition of Persistently Distressed Firms (PDF) rather than other commonly used deterministic indicators (i.e., Interest Covarage Ratio [ICR], negative added value, etc.). 
\par The first and more obvious advantage is that the PDF indicator can be constructed even in the presence of missing data. As we show in the Section of the paper about missing data, there are significant missingness patterns in the two variables that compose the ICR indicator (EBIT and Interest Paid).
\par The second advantage is that, while ICR and the other indicators are based on a deterministic definition of zombies, PDF is based on a probabilistic definition that can be tuned to embody different "likelihoods" of being zombie.
\par The third advantage is that our PDF indicator can be constructed using the information coming from multiple indicators and not just using the information on a single one.
\par Beside these clear advantages, there are more subtle benefits that can be obtained by using PDF instead of ICR.
To highlight these advantages we focus on a particular dimension of our PDF definition. To be a PDF a firm needs to be at high risk of failure (but not failing) for three consecutive years. 
Our PDF definition focuses on those firms that "are predicted to fail, but are surviving" (following the ML literature we could call them \textit{false positives}). 
Hence, a good indicator of "\textit{zombieness}" should be able to discriminate between \textit{false positives} and \textit{true positives}.
\par In this spirit, we develop a two stage algorithm to highlight which are the best predictors of \textit{false positives}.
In the first stage, we train a Logit model to predict the probability of failure:
\begin{equation}
 f_{LOGIT}(x) = \hat{p}_i(Y_i = 1 | X_i = x),
\end{equation}
and to obtain the fitted values $\hat{y}_i$.
In the second stage, we fit a LASSO just on those observations with $\hat{y}_i=1$ (\textit{positives}) to get the most important predictors (namely, those with non-zero coefficient) for the \textit{false positives}.
\par In the following code chuncks the implementation of this "two-stage" algorithm.

## Load Packages and Data

In this chunk we load the packages and the data used for the analysis, and we split the overall sample in a \textit{training} and a \textit{test} set.

```{r results = 'hide', include = TRUE, message = FALSE, warning = FALSE}
options(java.parameters = "-Xmx50g")
library(rJava)
library(bartMachine)
library(haven)
library(plyr)
library(dplyr)
library(PRROC)
library(caret)
library(glmnet)

# Load Data
data <- read_dta("analysis_data_indicators.dta")

# Initialize Data
names(data)[names(data) == 'GUO___BvD_ID_number'] <- 'guo'
data$control <- ifelse(data$guo=="", 0, 1)
data$nace <- as.factor(data$nace)
data$area <- as.factor(data$area)
levels(data$nace) <- floor(as.numeric(levels(data$nace))/100) 

#OMIITED DATA
lagged_variables <- c("failure", "iso", "control", "nace",
                      "shareholders_funds", "added_value",
                      "cash_flow", "ebitda", "fin_rev",
                      "liquidity_ratio", "total_assets",
                      "depr", "long_term_debt", "employees",
                      "materials", "loans", "wage_bill",
                      "tfp_acf", "fixed_assets", "tax",
                      "current_liabilities", "current_assets",
                      "fin_expenses", "int_paid",
                      "solvency_ratio", "net_income",
                      "revenue", "consdummy", "capital_intensity",
                      "fin_cons100", "inv", "ICR_failure",
                      "interest_diff", "NEG_VA", "real_SA",
                      "Z_score", "misallocated_fixed",
                      "profitability", "area", "dummy_patents",
                      "dummy_trademark","financial_sustainability",
                      "liquidity_return", "int_fixed_assets")
omitted <- na.omit(data[lagged_variables])
predictors <- c("control", "nace", "shareholders_funds",
                "added_value", "cash_flow", "ebitda",
                "fin_rev", "liquidity_ratio", "total_assets",
                "depr", "long_term_debt", "employees",
                "materials", "loans", "wage_bill", "tfp_acf",
                "fixed_assets", "tax", "current_liabilities",
                "current_assets", "fin_expenses", "int_paid",
                "solvency_ratio", "net_income", "revenue",
                "consdummy", "capital_intensity", "fin_cons100",
                "inv", "ICR_failure", "interest_diff", "NEG_VA",
                "real_SA", "misallocated_fixed", "profitability",
                "area", "dummy_patents", "dummy_trademark",
                "financial_sustainability", "liquidity_return",
                "int_fixed_assets")
formula <- as.formula(paste("as.factor(failure) ~",
                            paste(predictors, collapse="+")))

### Define samples
set.seed(123)
train_sample <- sample(seq_len(nrow(omitted)), size = nrow(omitted)*0.5) 
train <- as.data.frame(omitted[train_sample,])
test <- as.data.frame(omitted[-train_sample,])
```

In this chunck we contruct the LOGIT model, we get the predicted probabilities and the confusion matrix.
We use as a threshold 0.3 (namely,  $\hat{p}_i(Y_i = 1 | X_i = x)>0.3 \rightarrow \hat{y}_i=1$), however this threshold can be moved up to 0.5 without any meaninful change. 

```{r include = TRUE, message = FALSE, warning = FALSE}
log <- glm(formula, family = binomial, data = train)
prob_pred <- predict(log, type = 'response', newdata = test)
prediction <- as.numeric(prob_pred > 0.3) # change up to 0.5
cmlog=table(test$failure,prediction)
cmlog
```

In this chunck we use a LASSO model to select the variables with the highest predictive power for \textit{false positives}.

```{r}
test$prediction <- prediction
positive <- test[which(test$prediction==1),]
positive$iso <- as.numeric(as.factor(positive$iso))
positive$control <- as.numeric(as.factor(positive$control))
x <- as.matrix(as.data.frame(lapply(positive[predictors], as.numeric)))
y <- as.numeric(positive$prediction==1 & positive$failure==0)

mod <- cv.glmnet(x , y, alpha=1)
as.matrix(coef(mod, mod$lambda.1se))
row.names(as.matrix(coef(mod, mod$lambda.1se)))[which(as.matrix(coef(mod, mod$lambda.1se))!=0)]
```

The indicator that seems to have the best disciminative power are: \textit{control, solvency ratio, BID, negative AV, profitability, area, liquidity}. Hence, these indicators are the best to capture the component of "resistence" among highly distressed firms that makes them zombies.
